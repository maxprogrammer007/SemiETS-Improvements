{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4ba6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\abhin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature map: torch.Size([1, 512, 7, 7])\n",
      "Log probs: torch.Size([1, 7, 38])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.backbone import Backbone\n",
    "from models.recognizer import CRNN\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "backbone = Backbone().to(device)\n",
    "recognizer = CRNN().to(device)\n",
    "\n",
    "dummy = torch.randn(1, 3, 224, 224).to(device)\n",
    "feat = backbone(dummy)\n",
    "log_probs = recognizer(feat)\n",
    "\n",
    "print(\"Feature map:\", feat.shape)\n",
    "print(\"Log probs:\", log_probs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e3dd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection weight: tensor([0.0474, 0.5000, 0.9526])\n",
      "Recognition weight: tensor([0.0419, 0.0421, 0.0441])\n",
      "Final weight: tensor([0.0020, 0.0210, 0.0420])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.reliability import detection_reliability, recognition_reliability, combine_reliability\n",
    "\n",
    "# fake detection confidence\n",
    "det_conf = torch.tensor([0.2, 0.5, 0.8])\n",
    "\n",
    "# fake recognition output\n",
    "log_probs = torch.randn(3, 10, 38).log_softmax(dim=-1)\n",
    "\n",
    "det_w = detection_reliability(det_conf)\n",
    "rec_w = recognition_reliability(log_probs)\n",
    "final_w = combine_reliability(det_w, rec_w)\n",
    "\n",
    "print(\"Detection weight:\", det_w)\n",
    "print(\"Recognition weight:\", rec_w)\n",
    "print(\"Final weight:\", final_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374da0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted CTC loss: 11.777215003967285\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from losses.weighted_loss import WeightedCTCLoss\n",
    "\n",
    "criterion = WeightedCTCLoss()\n",
    "\n",
    "# fake recognizer output\n",
    "T, B, V = 7, 3, 38\n",
    "log_probs = torch.randn(T, B, V).log_softmax(dim=-1)\n",
    "\n",
    "# fake targets\n",
    "targets = torch.randint(1, V, (12,))\n",
    "target_lengths = torch.tensor([4, 4, 4])\n",
    "input_lengths = torch.tensor([T, T, T])\n",
    "\n",
    "# fake weights\n",
    "weights = torch.tensor([0.1, 0.5, 1.0])\n",
    "\n",
    "loss = criterion(\n",
    "    log_probs,\n",
    "    targets,\n",
    "    input_lengths,\n",
    "    target_lengths,\n",
    "    weights\n",
    ")\n",
    "\n",
    "print(\"Weighted CTC loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de9ab23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSL loss: 0.29958102107048035\n",
      "Reliability weights: tensor([0.0031, 0.0251], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.backbone import Backbone\n",
    "from models.recognizer import CRNN\n",
    "from models.teacher_student import TeacherStudentSSL\n",
    "from losses.weighted_loss import WeightedCTCLoss\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "backbone = Backbone().to(device)\n",
    "recognizer = CRNN().to(device)\n",
    "criterion = WeightedCTCLoss()\n",
    "\n",
    "ssl_model = TeacherStudentSSL(\n",
    "    backbone,\n",
    "    recognizer,\n",
    "    criterion\n",
    ").to(device)\n",
    "\n",
    "# fake batch\n",
    "images = torch.randn(2, 3, 224, 224).to(device)\n",
    "det_conf = torch.tensor([0.3, 0.8]).to(device)\n",
    "\n",
    "T = 7\n",
    "targets = torch.randint(1, 38, (10,)).to(device)\n",
    "input_lengths = torch.tensor([T, T]).to(device)\n",
    "target_lengths = torch.tensor([5, 5]).to(device)\n",
    "\n",
    "loss, weights = ssl_model(\n",
    "    images,\n",
    "    det_conf,\n",
    "    targets,\n",
    "    input_lengths,\n",
    "    target_lengths\n",
    ")\n",
    "\n",
    "print(\"SSL loss:\", loss.item())\n",
    "print(\"Reliability weights:\", weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e1c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same object: False\n"
     ]
    }
   ],
   "source": [
    "s_param = next(ssl_model.student_recognizer.parameters())\n",
    "t_param = next(ssl_model.teacher_recognizer.parameters())\n",
    "\n",
    "print(\"Same object:\", s_param.data_ptr() == t_param.data_ptr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93189df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher param change magnitude: 2.960731251278048e-07\n"
     ]
    }
   ],
   "source": [
    "before = next(ssl_model.teacher_recognizer.parameters()).clone()\n",
    "\n",
    "ssl_model.update_teacher()\n",
    "\n",
    "after = next(ssl_model.teacher_recognizer.parameters())\n",
    "\n",
    "print(\"Teacher param change magnitude:\",\n",
    "      torch.norm(after - before).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30bfd8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.29958200454711914\n",
      "Weights: tensor([0.0031, 0.0251], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1123: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1410.)\n",
      "  result = _VF.lstm(\n"
     ]
    }
   ],
   "source": [
    "loss, weights = ssl_model(\n",
    "    images,\n",
    "    det_conf,\n",
    "    targets,\n",
    "    input_lengths,\n",
    "    target_lengths\n",
    ")\n",
    "\n",
    "print(\"Loss:\", loss.item())\n",
    "print(\"Weights:\", weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8e03bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def perturb_images(images, noise_std=0.02):\n",
    "    \"\"\"\n",
    "    Simple pixel-level perturbation\n",
    "    (acts as proxy for localization noise)\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(images) * noise_std\n",
    "    return (images + noise).clamp(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32b0ba64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 0.2995823621749878\n",
      "Weights: tensor([0.0031, 0.0251], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "loss, weights = ssl_model(\n",
    "    images,\n",
    "    det_conf,\n",
    "    targets,\n",
    "    input_lengths,\n",
    "    target_lengths\n",
    ")\n",
    "\n",
    "print(\"Total loss:\", loss.item())\n",
    "print(\"Weights:\", weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a8a886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "tensor([17, 15, 24, 11, 34, 19, 29, 30, 18, 15, 11, 30, 28, 15])\n"
     ]
    }
   ],
   "source": [
    "from data.ic15_subset import IC15Subset\n",
    "\n",
    "dataset = IC15Subset(\n",
    "    image_dir=\"D:\\\\semiETS stuffs\\\\semiets_scratch\\\\data\\\\ic15\\\\images\",\n",
    "    annotation_json=\"D:\\\\semiETS stuffs\\\\semiets_scratch\\\\data\\\\ic15\\\\ic15_subset.json\",\n",
    "    vocab=\"0123456789abcdefghijklmnopqrstuvwxyz\",\n",
    "    max_samples=5\n",
    ")\n",
    "\n",
    "sample = dataset[0]\n",
    "print(sample[\"images\"].shape)\n",
    "print(sample[\"targets\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af49e87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ic15_collate_fn' from 'data.ic15_subset' (d:\\semiETS stuffs\\semiets_scratch\\data\\ic15_subset.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mic15_subset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IC15Subset, ic15_collate_fn\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImport successful\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ic15_collate_fn' from 'data.ic15_subset' (d:\\semiETS stuffs\\semiets_scratch\\data\\ic15_subset.py)"
     ]
    }
   ],
   "source": [
    "from data.ic15_subset import IC15Subset, ic15_collate_fn\n",
    "print(\"Import successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63fb6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
